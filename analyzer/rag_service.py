import chromadb
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from typing import List, Dict
import hashlib
_embedding_model = None
class RAGService:
    def __init__(self, api_key: str, db_name: str = "news_db", model_name: str = "gemini-1.5-flash"):
        """
        åˆå§‹åŒ– RAG æœå‹™ï¼Œè¨­å®š ChromaDB å’Œ Gemini æ¨¡å‹ã€‚
        """
        self.db_name = db_name
        self.client = chromadb.Client()
        self.collection = self.client.get_or_create_collection(name=self.db_name)
        # self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        global _embedding_model
        if _embedding_model is None:
            raise RuntimeError("Embedding æ¨¡å‹å°šæœªè¼‰å…¥ã€‚è«‹ç¢ºèªæ‡‰ç”¨ç¨‹å¼å·²å•Ÿå‹•ã€‚")
        self.embedding_model = _embedding_model
        genai.configure(api_key=api_key)
        self.gemini_model = genai.GenerativeModel(model_name)
    
    def generate_unique_id(self, article: Dict) -> str:
        """
        ä½¿ç”¨æ–‡ç« çš„æ¨™é¡Œå’Œæ‘˜è¦ç”Ÿæˆä¸€å€‹ç©©å®šçš„å”¯ä¸€ IDã€‚
        """
        title = article.get('title', '')
        summary = article.get('summary', '')
        # çµåˆæ¨™é¡Œå’Œæ‘˜è¦ï¼Œä¸¦ä½¿ç”¨ SHA-256 é›œæ¹Š
        combined_text = f"{title}_{summary}"
        return hashlib.sha256(combined_text.encode('utf-8')).hexdigest()

    def add_articles(self, articles: List[Dict]):
        """
        å°‡æ–‡ç« è³‡æ–™è½‰æ›æˆå‘é‡ä¸¦å­˜å…¥ ChromaDBã€‚
        æ­¤å‡½å¼æœƒç‚ºæ¯ç¯‡æ–‡ç« ç”Ÿæˆä¸€å€‹å”¯ä¸€çš„ IDï¼Œä¸¦é¿å…é‡è¤‡æ·»åŠ ã€‚
        """
        print("ğŸ“¢ æ­£åœ¨é€²è¡Œè³‡æ–™ Embedding è™•ç†...")
        documents = []
        metadatas = []
        ids = []

        try:
            # å¾è³‡æ–™åº«ä¸­ç²å–æ‰€æœ‰å·²å­˜åœ¨çš„ ID
            existing_ids_in_db = set(self.collection.get(include=[])['ids'])
        except Exception:
            existing_ids_in_db = set()

        # ğŸ’¡ æ–°å¢ä¸€å€‹é›†åˆï¼Œç”¨æ–¼è¿½è¹¤ç•¶å‰æ‰¹æ¬¡ä¸­å·²è™•ç†çš„ ID
        ids_in_current_batch = set()

        for d in articles:
            # ç‚ºæ¯ç¯‡æ–‡ç« ç”Ÿæˆä¸€å€‹å”¯ä¸€çš„ ID
            article_id = self.generate_unique_id(d)
            
            # åªæœ‰ç•¶ ID ä¸å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­ AND ä¸å­˜åœ¨æ–¼ç•¶å‰æ‰¹æ¬¡ä¸­æ™‚æ‰é€²è¡Œæ·»åŠ 
            if article_id not in existing_ids_in_db and article_id not in ids_in_current_batch:
                # æª¢æŸ¥å¿…è¦çš„æ¬„ä½æ˜¯å¦å­˜åœ¨ï¼Œä»¥é˜² KeyError
                if 'summary' in d and 'title' in d:
                    documents.append(d['summary'])
                    metadatas.append({'title': d['title'], 'sentiment': d.get('sentiment'), 'category': d.get('category')})
                    ids.append(article_id)
                    # ğŸ’¡ å°‡ ID åŠ å…¥åˆ°ç•¶å‰æ‰¹æ¬¡çš„è¿½è¹¤é›†åˆä¸­
                    ids_in_current_batch.add(article_id)
                else:
                    print(f"âš ï¸ è­¦å‘Šï¼šæ–‡ç« ç¼ºå°‘ 'summary' æˆ– 'title' æ¬„ä½ï¼Œå·²è·³éï¼š{d}")
            else:
                # å¦‚æœæ–‡ç«  ID å·²å­˜åœ¨æ–¼è³‡æ–™åº«æˆ–ç•¶å‰æ‰¹æ¬¡ä¸­ï¼Œå‰‡è·³é
                pass # print(f"â„¹ï¸ æ–‡ç« å·²å­˜åœ¨æˆ–ç‚ºé‡è¤‡ï¼Œå·²è·³é ID: {article_id}")
        
        if documents:
            embeddings = self.embedding_model.encode(documents).tolist()
            self.collection.add(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
            print(f"âœ… {len(documents)} ç¯‡æ–‡ç« å·²æˆåŠŸåŠ å…¥è³‡æ–™åº«ã€‚")
        else:
            print("â„¹ï¸ æ²’æœ‰æ–°æ–‡ç« éœ€è¦åŠ å…¥è³‡æ–™åº«ã€‚")

    def query(self, user_query: str, n_results: int = 5) -> str:
        """
        è™•ç†ä½¿ç”¨è€…æŸ¥è©¢ï¼Œä¸¦ä½¿ç”¨ RAG ç”Ÿæˆæœ€çµ‚å›ç­”ã€‚
        """
        print("â¡ï¸ æ¥æ”¶åˆ°æŸ¥è©¢ï¼Œé–‹å§‹æª¢ç´¢...")
        try:
            results = self.collection.query(
                query_texts=[user_query],
                n_results=n_results
            )
            relevant_docs = results['documents'][0]
            print("âœ… æª¢ç´¢å®Œæˆï¼Œæ‰¾åˆ°æ–‡ä»¶æ•¸é‡ï¼š", len(relevant_docs))
        except Exception as e:
            print(f"âŒ æª¢ç´¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return "æŸ¥è©¢è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        if not relevant_docs:
            return "å¾ˆæŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•åœ¨ç¾æœ‰è³‡æ–™ä¸­æ‰¾åˆ°ç›¸é—œè³‡è¨Šã€‚"

        context_str = "\n".join(relevant_docs)
        prompt = f"""
        ä½ æ˜¯ä¸€ä½æ“…é•·åˆ©ç”¨å¤§æ•¸æ“šåˆ†ææ™‚äº‹çš„åˆ†æå¸«ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›è¿‘æœŸæ–°èæ‘˜è¦è³‡æ–™ï¼Œ
        è«‹æ ¹æ“šé€™äº›è³‡æ–™å›ç­”ä½¿ç”¨è€…çš„å•é¡Œï¼Œä¸è¦ç”¢å‡ºè·Ÿå•é¡Œä¸ç›¸é—œçš„å…§å®¹ï¼Œ
        ç›´æ¥çµ¦å›ç­”ï¼Œä¸ç”¨å‰è¨€ã€‚
        ---
        {context_str}
        ---
        ä½¿ç”¨è€…å•é¡Œï¼š{user_query}
        è«‹ç”¨æ¢åˆ—æ–¹å¼å›ç­”å•é¡Œï¼Œä¸¦æŒ‡å‡ºæ•´é«”æƒ…ç·’è¶¨å‹¢èˆ‡è­°é¡Œé‡é»,æœ€å¾Œçµ¦å‡ºçµè«–ã€‚
        """.strip()
        
        try:
            print("â¡ï¸ æ­£åœ¨å‘¼å« Gemini API é€²è¡Œç”Ÿæˆ...")
            response = self.gemini_model.generate_content(prompt)
            print("âœ… Gemini å›æ‡‰æˆåŠŸã€‚")
            return response.text
        except Exception as e:
            print(f"âŒ Gemini API å‘¼å«å¤±æ•—: {e}")
            return f"ç”Ÿæˆå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"